{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e665ee4c",
   "metadata": {},
   "source": [
    "Must measure the accuracy of model only on the validation set.\n",
    "\n",
    "Over-fitting: If you train for too long, with not enough data, you'll see the accuracy of your model start to get worse. Training model in such way that it remembers specific features of the input data, rather than generalising well to data not seen during training.\n",
    "\n",
    "epoch: looked at every image once - and to print out information on how the model is doing (i.e. erorr rate on the validation set). \n",
    "\n",
    "architecture: the template of te model that we're trying to fit, the actual mathematical funciton that we're passing the input data and parameters to.\n",
    "\n",
    "metric: function that measures the quality of the models predictions using the validation set, printed after each epoch.\n",
    "\n",
    "loss: function that the computer/algorithm is using to update the parameters. Cannot use metrics (i.e. erorr rate) as change is erorr rate will not change the parameters sometimes. \n",
    "\n",
    "\n",
    "split data into third set callde the training set - thus avoiding to optimise model for validation set. this set will be used after project is finished. \n",
    "\n",
    "\n",
    "Transfer learning: using a pretrained modl for a task different to what is it was originally trained for (i.e. learn.fine_tune(1)). Start with these weights from pre-trained model and train more epoch's on relevant data to come up with good model. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730219c",
   "metadata": {},
   "source": [
    " p-value is the probability of the an observed (or more extereme) result assuming that the null hypothesis is true. \n",
    " \n",
    " Should not use p-values\n",
    " \n",
    " - p-values can indicate how incompatible that data are with a specified statistical model. \n",
    " \n",
    " - p-values do not meauser the probability that the studided hypothesis is ture, or the proabability that the data were produced by random chance alone. \n",
    " \n",
    " - conclusions and business or policy dectisions should not be based only on whether a p-value passes a specific threshold. \n",
    " \n",
    " - Does not measure the size of an effect or the importance of a result. \n",
    " \n",
    " - Does not provide a good measure of evidence regarding a model or hypothesis. \n",
    " \n",
    " \n",
    " relationship could be random - if we ran some simulation on random normal distribution of data points generated. \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03e21f",
   "metadata": {},
   "source": [
    "#### Howard's drivetrain approach \n",
    "\n",
    "Going beyond predictions and turning predictions into decisions/actions. \n",
    "https://www.oreilly.com/radar/drivetrain-approach-data-products/\n",
    "http://radar.oreilly.com/2012/03/drivetrain-approach-data-products.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to data loaders \n",
    "\n",
    "bears = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), # tuples of indendent(images)/dependednt (type of bear) variables\n",
    "    get_items=get_image_files, #path and returns a list of all the images in the path\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
